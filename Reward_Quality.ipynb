{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-05T12:26:27.614022948Z",
     "start_time": "2023-09-05T12:26:15.701114492Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rid/Soft/anaconda3/envs/sm_bachelor/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/rid/Soft/anaconda3/envs/sm_bachelor/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c104warnERKNS_7WarningE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/home/rid/Soft/anaconda3/envs/sm_bachelor/lib/python3.9/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: \u001B[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001B[0m\n",
      "  @numba.jit()\n",
      "/home/rid/Soft/anaconda3/envs/sm_bachelor/lib/python3.9/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: \u001B[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001B[0m\n",
      "  @numba.jit()\n",
      "/home/rid/Soft/anaconda3/envs/sm_bachelor/lib/python3.9/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: \u001B[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001B[0m\n",
      "  @numba.jit()\n",
      "/home/rid/Soft/anaconda3/envs/sm_bachelor/lib/python3.9/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: \u001B[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001B[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from darts.models.forecasting.nhits import NHiTSModel\n",
    "from darts import TimeSeries\n",
    "import torch\n",
    "from typing import Callable\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helpers import predict, load_agent, quality, clip\n",
    "from preprocess import preprocess_stats\n",
    "from rl.sim_enviroment import SimulatedCustomEnv\n",
    "\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "from evidently.options import DataDriftOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "\n",
    "def optimize_params(data: pd.DataFrame, preprocess: Callable = preprocess_stats, device='cpu') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run and evaluate agent.\n",
    "\n",
    "    :param data:        raw observations in pandas DataFrame\n",
    "    :return:            result saves to the same path as input\n",
    "\n",
    "    Args:\n",
    "        preprocess: function to preprocess data\n",
    "    \"\"\"\n",
    "    columns = ['Cell ID', 'LAC', 'HR Usage Rate', 'TCH Blocking Rate, BH', 'Number of Available\\nTCH',\n",
    "               'TCH Traffic (Erl), BH', 'Lower_limit', 'Upper_limit']\n",
    "\n",
    "    df = preprocess(data, columns)\n",
    "    obs_array = df.drop(columns=['Cell ID', 'LAC'], errors='ignore')\n",
    "    obs_array.rename_axis(None, axis=1, inplace=True)\n",
    "    obs_array.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    agent = load_agent('sac_last_60_50d_exp-r.pt', 'pt')\n",
    "    state_predictor = NHiTSModel.load_from_checkpoint(\"nhits_35lw_2l_1b_3s_35d_no_TB\", \"state_predictor\", best=True, map_location=device)\n",
    "\n",
    "    # # 'HR Usage Rate', 'TCH Blocking Rate, BH'\n",
    "    # self.current_state = series[randint(0, len(series))].head(n_past)\n",
    "    # # 'Number of Available\\nTCH', 'TCH Traffic (Erl), BH', 'Param 1',  'Param 2'\n",
    "    # self.cov = covariates[0].head(n_past)\n",
    "\n",
    "\n",
    "    lower_limits = []\n",
    "    upper_limits = []\n",
    "    qualities = []\n",
    "    new_states = []\n",
    "\n",
    "    # 'HR Usage Rate', 'TCH Blocking Rate, BH'\n",
    "    current_state = obs_array.iloc[:7, :2]\n",
    "    cov = obs_array.iloc[:7, -4:]\n",
    "\n",
    "    # print(TimeSeries.from_dataframe(obs_array.iloc[:, :2]))\n",
    "    # print(len(TimeSeries.from_dataframe(obs_array.iloc[:, :2])))\n",
    "\n",
    "    # setting env for reward calculation\n",
    "    environment = SimulatedCustomEnv(\n",
    "        state_predictor,\n",
    "        np.array([1,1]),\n",
    "        TimeSeries.from_dataframe(obs_array.iloc[:, :2]),\n",
    "        TimeSeries.from_dataframe(obs_array.iloc[:, -4:]),\n",
    "        7\n",
    "    )\n",
    "    obs = environment.reset()\n",
    "    mom_reward = []\n",
    "\n",
    "    for i, row in enumerate(obs_array.iloc[7:].values):\n",
    "        # print('Curr_state=', current_state.shape)\n",
    "\n",
    "        a1, a2 = predict(row, agent)\n",
    "        lower = clip(int(row[-2] + a1 * 30))\n",
    "        upper = clip(int(row[-1] + a2 * 30))\n",
    "\n",
    "        # compure reward\n",
    "        new_state, reward, done, info = environment.step(np.array([a1, a2]))\n",
    "        mom_reward.append(reward)\n",
    "\n",
    "        # Compute quality\n",
    "        qualities.append(\n",
    "            quality(blocking=row[1], ch=row[2], traffic=row[3], param1=row[-2], param2=row[-1], prparam1=lower,\n",
    "                    prparam2=upper)\n",
    "        )\n",
    "\n",
    "        cov.iloc[-1, -2:] = (lower, upper)\n",
    "        # print(cov)\n",
    "        # n for number of states to predict\n",
    "        # current_state.rename_axis(None, axis=1, inplace=True)\n",
    "        # current_state.reset_index(drop=True, inplace=True)\n",
    "        pred_state = state_predictor.predict(n=1, series=TimeSeries.from_dataframe(current_state),\n",
    "                                             past_covariates=TimeSeries.from_dataframe(cov), verbose=False)\n",
    "        new_states.append(pred_state)\n",
    "\n",
    "        lower_limits.append(lower)\n",
    "        upper_limits.append(upper)\n",
    "\n",
    "        current_state = pd.concat([current_state.iloc[1:], obs_array.iloc[i +7: i+8, :2]], axis=0, join='inner')\n",
    "        # print(current_state)\n",
    "\n",
    "        cov = obs_array.iloc[i+1: i +8, -4:]\n",
    "    # df['Lower_limit_Gen'], df['Upper_limit_Gen'], df['Limit_quality_Gen'] = lower_limits, upper_limits, qualities\n",
    "    # df[\"Quality Rate\"] = 1 - (2*df['HR Usage Rate']/100 + np.log(df['TCH Blocking Rate, BH'] + 1))/(1 + np.log(101))\n",
    "\n",
    "    states_df = pd.concat(list(map(lambda x: x.pd_dataframe(), new_states)))\n",
    "    states_df[\"Quality Rate\"] = 1 - (2*states_df['HR Usage Rate']/100 + np.log(states_df['TCH Blocking Rate, BH'] + 1))/(1 + np.log(101))\n",
    "    states_df['cum_reward'] = np.cumsum(mom_reward)\n",
    "    states_df['mom_reward'] = mom_reward\n",
    "\n",
    "    return states_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T07:26:35.889014226Z",
     "start_time": "2023-09-05T07:26:35.868552639Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def preprocess_full(data: pd.DataFrame, cols: List[str]=None):\n",
    "    df = data.copy()\n",
    "    cols = ['HR Usage Rate', 'TCH Blocking Rate, BH', 'Number of Available\\nTCH',\n",
    "               'TCH Traffic (Erl), BH', 'Lower_limit', 'Upper_limit']\n",
    "    df.drop(columns='DATA', inplace=True)\n",
    "    df.rename(columns={'Param 1': cols[-2], 'Param 2': cols[-1]}, inplace=True)\n",
    "    return df[cols]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T07:11:48.461827099Z",
     "start_time": "2023-09-05T07:11:48.425135259Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/dataset_full.csv', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T07:11:50.273298504Z",
     "start_time": "2023-09-05T07:11:49.210379725Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "cell_list = list(map(lambda x: x[0], df[['Cell ID']].value_counts().index[:10].tolist()))\n",
    "curr = df[df['Cell ID'].isin(cell_list)]\n",
    "reff = df[~df['Cell ID'].isin(cell_list)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T07:11:51.064182578Z",
     "start_time": "2023-09-05T07:11:50.975820481Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:55<00:00, 57.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 4s, sys: 4.99 s, total: 3min 9s\n",
      "Wall time: 1min 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scores = []\n",
    "\n",
    "import logging\n",
    "# logging.getLogger(\"pytorch_lightning.utilities.rank_zero\").setLevel(logging.WARNING)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    logging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)\n",
    "\n",
    "    for cell in tqdm(df[['Cell ID']].value_counts().keys()[:2]):\n",
    "        cell_data = df[df['Cell ID'] == cell]\n",
    "\n",
    "        data_drift_report = Report(metrics=[\n",
    "            DataDriftPreset(),\n",
    "        ])\n",
    "        data_drift_report.run(reference_data=reff, current_data=cell_data,)\n",
    "        drift = data_drift_report.as_dict()['metrics'][0]['result']['share_of_drifted_columns']\n",
    "\n",
    "        states = optimize_params(cell_data, preprocess=preprocess_full)\n",
    "\n",
    "        scores.append({\n",
    "            'cell_id': cell,\n",
    "            'drift_score': drift,\n",
    "            'quality_avg': states['Quality Rate'].mean(),\n",
    "            'quality_min': states['Quality Rate'].min(),\n",
    "            'quality_max': states['Quality Rate'].max(),\n",
    "            'quality_std': states['Quality Rate'].std(),\n",
    "            'cum_reward_avg': states['cum_reward'].mean(),\n",
    "            'cum_reward_max': states['cum_reward'].max(),\n",
    "            'cum_reward_std': states['cum_reward'].std(),\n",
    "            'mom_reward_avg': states['mom_reward'].mean(),\n",
    "            'mom_reward_min': states['mom_reward'].min(),\n",
    "            'mom_reward_max': states['mom_reward'].max(),\n",
    "            'mom_reward_std': states['mom_reward'].std(),\n",
    "        })\n",
    "\n",
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df.to_csv('drift_scores_rewards_300.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T07:13:51.938867756Z",
     "start_time": "2023-09-05T07:11:56.542529307Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "    cell_id  drift_score  quality_avg  quality_min  quality_max  quality_std  \\\n0   (1946,)        0.750     0.874185     0.734750     1.688068     0.056923   \n1   (1945,)        0.750     0.881187     0.707820     1.069511     0.036198   \n2   (1947,)        1.000     0.842564     0.679234     0.999759     0.047799   \n3   (1941,)        0.875     0.852576     0.678216     1.311538     0.069046   \n4   (1943,)        0.875     0.806072     0.668687     1.095661     0.087994   \n5   (1942,)        0.875     0.855051     0.722536     1.801337     0.066887   \n6  (13313,)        0.875     0.777178     0.716126     1.150875     0.034356   \n7  (13312,)        0.875     0.827807     0.683533     1.014011     0.051529   \n8  (13311,)        0.875     0.766741     0.637207     1.072541     0.050358   \n9  (22953,)        0.750     0.906204     0.752501     1.126982     0.035694   \n\n   cum_reward_avg  cum_reward_max  cum_reward_std  mom_reward_avg  \\\n0   -3.575299e+06             -45    3.179021e+06   -17657.961730   \n1   -3.039105e+06             -50    2.671801e+06   -14785.532446   \n2   -1.147139e+06             -10    1.042341e+06    -5578.850000   \n3   -3.435891e+06             -45    3.090324e+06   -17293.177258   \n4   -3.560386e+06             -50    3.162241e+06   -17649.991639   \n5   -3.499136e+06             -60    3.084310e+06   -17133.244147   \n6   -2.864914e+06             -45    2.320279e+06   -12764.756711   \n7   -1.365232e+06              20    1.551018e+06    -8932.390940   \n8   -5.250962e+05              15    4.510842e+05    -2500.184564   \n9   -3.266940e+06             -45    2.888713e+06   -16287.254237   \n\n   mom_reward_min  mom_reward_max  mom_reward_std  \n0          -34750             -45    10037.161238  \n1          -28105             -50     8152.344845  \n2           -9795             -10     3138.280158  \n3          -34560             -45    10108.637397  \n4          -34895             -50    10007.992846  \n5          -32395             -60     9472.583864  \n6          -21165             -45     5655.187080  \n7          -23890              10     7760.800072  \n8           -4505              10     1293.218758  \n9          -30980             -45     9091.123056  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cell_id</th>\n      <th>drift_score</th>\n      <th>quality_avg</th>\n      <th>quality_min</th>\n      <th>quality_max</th>\n      <th>quality_std</th>\n      <th>cum_reward_avg</th>\n      <th>cum_reward_max</th>\n      <th>cum_reward_std</th>\n      <th>mom_reward_avg</th>\n      <th>mom_reward_min</th>\n      <th>mom_reward_max</th>\n      <th>mom_reward_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(1946,)</td>\n      <td>0.750</td>\n      <td>0.874185</td>\n      <td>0.734750</td>\n      <td>1.688068</td>\n      <td>0.056923</td>\n      <td>-3.575299e+06</td>\n      <td>-45</td>\n      <td>3.179021e+06</td>\n      <td>-17657.961730</td>\n      <td>-34750</td>\n      <td>-45</td>\n      <td>10037.161238</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(1945,)</td>\n      <td>0.750</td>\n      <td>0.881187</td>\n      <td>0.707820</td>\n      <td>1.069511</td>\n      <td>0.036198</td>\n      <td>-3.039105e+06</td>\n      <td>-50</td>\n      <td>2.671801e+06</td>\n      <td>-14785.532446</td>\n      <td>-28105</td>\n      <td>-50</td>\n      <td>8152.344845</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(1947,)</td>\n      <td>1.000</td>\n      <td>0.842564</td>\n      <td>0.679234</td>\n      <td>0.999759</td>\n      <td>0.047799</td>\n      <td>-1.147139e+06</td>\n      <td>-10</td>\n      <td>1.042341e+06</td>\n      <td>-5578.850000</td>\n      <td>-9795</td>\n      <td>-10</td>\n      <td>3138.280158</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(1941,)</td>\n      <td>0.875</td>\n      <td>0.852576</td>\n      <td>0.678216</td>\n      <td>1.311538</td>\n      <td>0.069046</td>\n      <td>-3.435891e+06</td>\n      <td>-45</td>\n      <td>3.090324e+06</td>\n      <td>-17293.177258</td>\n      <td>-34560</td>\n      <td>-45</td>\n      <td>10108.637397</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(1943,)</td>\n      <td>0.875</td>\n      <td>0.806072</td>\n      <td>0.668687</td>\n      <td>1.095661</td>\n      <td>0.087994</td>\n      <td>-3.560386e+06</td>\n      <td>-50</td>\n      <td>3.162241e+06</td>\n      <td>-17649.991639</td>\n      <td>-34895</td>\n      <td>-50</td>\n      <td>10007.992846</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>(1942,)</td>\n      <td>0.875</td>\n      <td>0.855051</td>\n      <td>0.722536</td>\n      <td>1.801337</td>\n      <td>0.066887</td>\n      <td>-3.499136e+06</td>\n      <td>-60</td>\n      <td>3.084310e+06</td>\n      <td>-17133.244147</td>\n      <td>-32395</td>\n      <td>-60</td>\n      <td>9472.583864</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>(13313,)</td>\n      <td>0.875</td>\n      <td>0.777178</td>\n      <td>0.716126</td>\n      <td>1.150875</td>\n      <td>0.034356</td>\n      <td>-2.864914e+06</td>\n      <td>-45</td>\n      <td>2.320279e+06</td>\n      <td>-12764.756711</td>\n      <td>-21165</td>\n      <td>-45</td>\n      <td>5655.187080</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>(13312,)</td>\n      <td>0.875</td>\n      <td>0.827807</td>\n      <td>0.683533</td>\n      <td>1.014011</td>\n      <td>0.051529</td>\n      <td>-1.365232e+06</td>\n      <td>20</td>\n      <td>1.551018e+06</td>\n      <td>-8932.390940</td>\n      <td>-23890</td>\n      <td>10</td>\n      <td>7760.800072</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>(13311,)</td>\n      <td>0.875</td>\n      <td>0.766741</td>\n      <td>0.637207</td>\n      <td>1.072541</td>\n      <td>0.050358</td>\n      <td>-5.250962e+05</td>\n      <td>15</td>\n      <td>4.510842e+05</td>\n      <td>-2500.184564</td>\n      <td>-4505</td>\n      <td>10</td>\n      <td>1293.218758</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>(22953,)</td>\n      <td>0.750</td>\n      <td>0.906204</td>\n      <td>0.752501</td>\n      <td>1.126982</td>\n      <td>0.035694</td>\n      <td>-3.266940e+06</td>\n      <td>-45</td>\n      <td>2.888713e+06</td>\n      <td>-16287.254237</td>\n      <td>-30980</td>\n      <td>-45</td>\n      <td>9091.123056</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores_df = pd.read_csv('drift_scores_rewards.csv', index_col=0)\n",
    "scores_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T07:17:56.874920782Z",
     "start_time": "2023-09-04T07:17:56.839649806Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                drift_score  quality_avg  quality_min  quality_max  \\\ndrift_score        1.000000    -0.550605    -0.605572    -0.258672   \nquality_avg       -0.550605     1.000000     0.698381     0.303663   \nquality_min       -0.605572     0.698381     1.000000     0.467612   \nquality_max       -0.258672     0.303663     0.467612     1.000000   \nquality_std        0.269613    -0.158696    -0.377524     0.323319   \ncum_reward_avg     0.528747    -0.499749    -0.636475    -0.563363   \ncum_reward_max     0.407681    -0.446164    -0.612046    -0.528408   \ncum_reward_std    -0.535117     0.543064     0.626828     0.561030   \nmom_reward_avg     0.541696    -0.546772    -0.625488    -0.555300   \nmom_reward_min     0.537498    -0.565781    -0.561378    -0.516847   \nmom_reward_max     0.431527    -0.449636    -0.623015    -0.540661   \nmom_reward_std    -0.518617     0.595814     0.545800     0.497546   \n\n                quality_std  cum_reward_avg  cum_reward_max  cum_reward_std  \\\ndrift_score        0.269613        0.528747        0.407681       -0.535117   \nquality_avg       -0.158696       -0.499749       -0.446164        0.543064   \nquality_min       -0.377524       -0.636475       -0.612046        0.626828   \nquality_max        0.323319       -0.563363       -0.528408        0.561030   \nquality_std        1.000000       -0.303255       -0.185431        0.344766   \ncum_reward_avg    -0.303255        1.000000        0.931871       -0.991554   \ncum_reward_max    -0.185431        0.931871        1.000000       -0.886365   \ncum_reward_std     0.344766       -0.991554       -0.886365        1.000000   \nmom_reward_avg    -0.347661        0.988429        0.874997       -0.999600   \nmom_reward_min    -0.412466        0.924603        0.740686       -0.965525   \nmom_reward_max    -0.196013        0.947229        0.997704       -0.907093   \nmom_reward_std     0.419151       -0.882294       -0.678855        0.935646   \n\n                mom_reward_avg  mom_reward_min  mom_reward_max  mom_reward_std  \ndrift_score           0.541696        0.537498        0.431527       -0.518617  \nquality_avg          -0.546772       -0.565781       -0.449636        0.595814  \nquality_min          -0.625488       -0.561378       -0.623015        0.545800  \nquality_max          -0.555300       -0.516847       -0.540661        0.497546  \nquality_std          -0.347661       -0.412466       -0.196013        0.419151  \ncum_reward_avg        0.988429        0.924603        0.947229       -0.882294  \ncum_reward_max        0.874997        0.740686        0.997704       -0.678855  \ncum_reward_std       -0.999600       -0.965525       -0.907093        0.935646  \nmom_reward_avg        1.000000        0.971219        0.896998       -0.943279  \nmom_reward_min        0.971219        1.000000        0.772915       -0.994334  \nmom_reward_max        0.896998        0.772915        1.000000       -0.713925  \nmom_reward_std       -0.943279       -0.994334       -0.713925        1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>drift_score</th>\n      <th>quality_avg</th>\n      <th>quality_min</th>\n      <th>quality_max</th>\n      <th>quality_std</th>\n      <th>cum_reward_avg</th>\n      <th>cum_reward_max</th>\n      <th>cum_reward_std</th>\n      <th>mom_reward_avg</th>\n      <th>mom_reward_min</th>\n      <th>mom_reward_max</th>\n      <th>mom_reward_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>drift_score</th>\n      <td>1.000000</td>\n      <td>-0.550605</td>\n      <td>-0.605572</td>\n      <td>-0.258672</td>\n      <td>0.269613</td>\n      <td>0.528747</td>\n      <td>0.407681</td>\n      <td>-0.535117</td>\n      <td>0.541696</td>\n      <td>0.537498</td>\n      <td>0.431527</td>\n      <td>-0.518617</td>\n    </tr>\n    <tr>\n      <th>quality_avg</th>\n      <td>-0.550605</td>\n      <td>1.000000</td>\n      <td>0.698381</td>\n      <td>0.303663</td>\n      <td>-0.158696</td>\n      <td>-0.499749</td>\n      <td>-0.446164</td>\n      <td>0.543064</td>\n      <td>-0.546772</td>\n      <td>-0.565781</td>\n      <td>-0.449636</td>\n      <td>0.595814</td>\n    </tr>\n    <tr>\n      <th>quality_min</th>\n      <td>-0.605572</td>\n      <td>0.698381</td>\n      <td>1.000000</td>\n      <td>0.467612</td>\n      <td>-0.377524</td>\n      <td>-0.636475</td>\n      <td>-0.612046</td>\n      <td>0.626828</td>\n      <td>-0.625488</td>\n      <td>-0.561378</td>\n      <td>-0.623015</td>\n      <td>0.545800</td>\n    </tr>\n    <tr>\n      <th>quality_max</th>\n      <td>-0.258672</td>\n      <td>0.303663</td>\n      <td>0.467612</td>\n      <td>1.000000</td>\n      <td>0.323319</td>\n      <td>-0.563363</td>\n      <td>-0.528408</td>\n      <td>0.561030</td>\n      <td>-0.555300</td>\n      <td>-0.516847</td>\n      <td>-0.540661</td>\n      <td>0.497546</td>\n    </tr>\n    <tr>\n      <th>quality_std</th>\n      <td>0.269613</td>\n      <td>-0.158696</td>\n      <td>-0.377524</td>\n      <td>0.323319</td>\n      <td>1.000000</td>\n      <td>-0.303255</td>\n      <td>-0.185431</td>\n      <td>0.344766</td>\n      <td>-0.347661</td>\n      <td>-0.412466</td>\n      <td>-0.196013</td>\n      <td>0.419151</td>\n    </tr>\n    <tr>\n      <th>cum_reward_avg</th>\n      <td>0.528747</td>\n      <td>-0.499749</td>\n      <td>-0.636475</td>\n      <td>-0.563363</td>\n      <td>-0.303255</td>\n      <td>1.000000</td>\n      <td>0.931871</td>\n      <td>-0.991554</td>\n      <td>0.988429</td>\n      <td>0.924603</td>\n      <td>0.947229</td>\n      <td>-0.882294</td>\n    </tr>\n    <tr>\n      <th>cum_reward_max</th>\n      <td>0.407681</td>\n      <td>-0.446164</td>\n      <td>-0.612046</td>\n      <td>-0.528408</td>\n      <td>-0.185431</td>\n      <td>0.931871</td>\n      <td>1.000000</td>\n      <td>-0.886365</td>\n      <td>0.874997</td>\n      <td>0.740686</td>\n      <td>0.997704</td>\n      <td>-0.678855</td>\n    </tr>\n    <tr>\n      <th>cum_reward_std</th>\n      <td>-0.535117</td>\n      <td>0.543064</td>\n      <td>0.626828</td>\n      <td>0.561030</td>\n      <td>0.344766</td>\n      <td>-0.991554</td>\n      <td>-0.886365</td>\n      <td>1.000000</td>\n      <td>-0.999600</td>\n      <td>-0.965525</td>\n      <td>-0.907093</td>\n      <td>0.935646</td>\n    </tr>\n    <tr>\n      <th>mom_reward_avg</th>\n      <td>0.541696</td>\n      <td>-0.546772</td>\n      <td>-0.625488</td>\n      <td>-0.555300</td>\n      <td>-0.347661</td>\n      <td>0.988429</td>\n      <td>0.874997</td>\n      <td>-0.999600</td>\n      <td>1.000000</td>\n      <td>0.971219</td>\n      <td>0.896998</td>\n      <td>-0.943279</td>\n    </tr>\n    <tr>\n      <th>mom_reward_min</th>\n      <td>0.537498</td>\n      <td>-0.565781</td>\n      <td>-0.561378</td>\n      <td>-0.516847</td>\n      <td>-0.412466</td>\n      <td>0.924603</td>\n      <td>0.740686</td>\n      <td>-0.965525</td>\n      <td>0.971219</td>\n      <td>1.000000</td>\n      <td>0.772915</td>\n      <td>-0.994334</td>\n    </tr>\n    <tr>\n      <th>mom_reward_max</th>\n      <td>0.431527</td>\n      <td>-0.449636</td>\n      <td>-0.623015</td>\n      <td>-0.540661</td>\n      <td>-0.196013</td>\n      <td>0.947229</td>\n      <td>0.997704</td>\n      <td>-0.907093</td>\n      <td>0.896998</td>\n      <td>0.772915</td>\n      <td>1.000000</td>\n      <td>-0.713925</td>\n    </tr>\n    <tr>\n      <th>mom_reward_std</th>\n      <td>-0.518617</td>\n      <td>0.595814</td>\n      <td>0.545800</td>\n      <td>0.497546</td>\n      <td>0.419151</td>\n      <td>-0.882294</td>\n      <td>-0.678855</td>\n      <td>0.935646</td>\n      <td>-0.943279</td>\n      <td>-0.994334</td>\n      <td>-0.713925</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df[scores_df.columns[1:]].corr()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T07:18:27.279593793Z",
     "start_time": "2023-09-04T07:18:27.239604109Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "1043"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Cell ID'].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T10:19:54.862189704Z",
     "start_time": "2023-09-04T10:19:54.837915222Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "300 / len(df['Cell ID'].unique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "scores_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "loggers = [logging.getLogger(name) for name in logging.root.manager.loggerDict]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "with open('loggers.txt', 'w') as f:\n",
    "    for item in loggers:\n",
    "        # write each item on a new line\n",
    "        f.write(\"%s\\n\" % item)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "class LessThanFilter(logging.Filter):\n",
    "    def __init__(self, exclusive_maximum, name=\"\"):\n",
    "        super(LessThanFilter, self).__init__(name)\n",
    "        self.max_level = exclusive_maximum\n",
    "\n",
    "    def filter(self, record):\n",
    "        #non-zero return means we log this message\n",
    "        return 1 if record.levelno < self.max_level else 0\n",
    "\n",
    "logging.getLogger(\"pytorch_lightning.utilities.rank_zero\").addFilter(LessThanFilter(logging.ERROR))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T11:26:40.553508627Z",
     "start_time": "2023-09-04T11:26:40.544830270Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "logging.getLogger(\"pytorch_lightning.utilities.rank_zero\").error('asd')\n",
    "logging.getLogger(\"pytorch_lightning.utilities.rank_zero\").error('asd')\n",
    "logging.getLogger(\"pytorch_lightning.utilities.rank_zero\").error('asd')\n",
    "logging.getLogger(\"pytorch_lightning.utilities.rank_zero\").error('asd')\n",
    "logging.getLogger(\"pytorch_lightning.utilities.rank_zero\").error('asd')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T11:26:53.571900441Z",
     "start_time": "2023-09-04T11:26:53.562437112Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "('/home/rid/Soft/anaconda3/envs/sm_bachelor/lib/python3.9/site-packages/IPython/core/interactiveshell.py',\n 3448,\n 'run_ast_nodes',\n None)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.getLogger(\"pytorch_lightning.utilities.rank_zero\").findCaller()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T11:29:41.736301618Z",
     "start_time": "2023-09-04T11:29:41.707082771Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.43 s, sys: 212 ms, total: 6.65 s\n",
      "Wall time: 6.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_drift_report = Report(metrics=[\n",
    "    DataDriftPreset(),\n",
    "])\n",
    "data_drift_report.run(reference_data=reff, current_data=cell_data,)\n",
    "drift = data_drift_report.as_dict()['metrics'][0]['result']['share_of_drifted_columns']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T12:42:10.581486699Z",
     "start_time": "2023-09-04T12:42:03.780724117Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.22 s, sys: 168 ms, total: 6.39 s\n",
      "Wall time: 6.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_drift_report.run(reference_data=reff, current_data=cell_data,)\n",
    "drift = data_drift_report.as_dict()['metrics'][0]['result']['share_of_drifted_columns']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T12:42:17.073199653Z",
     "start_time": "2023-09-04T12:42:10.585728730Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.4 s, sys: 1.72 s, total: 44.1 s\n",
      "Wall time: 44.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    states = optimize_params(cell_data, preprocess=preprocess_full)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T12:43:01.223134380Z",
     "start_time": "2023-09-04T12:42:17.079752110Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T07:10:50.869794388Z",
     "start_time": "2023-09-05T07:10:50.856997580Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 27s, sys: 2.28 s, total: 1min 30s\n",
      "Wall time: 54.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    states = optimize_params(cell_data, preprocess=preprocess_full)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T07:27:42.421733251Z",
     "start_time": "2023-09-05T07:26:47.911421343Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 1.81 s, total: 1min 25s\n",
      "Wall time: 48.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    states = optimize_params(cell_data, preprocess=preprocess_full, device='cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T07:28:30.701085476Z",
     "start_time": "2023-09-05T07:27:42.467681715Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "data = pd.read_csv('drift_scores_rewards_all.csv', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T12:29:00.932055311Z",
     "start_time": "2023-09-05T12:29:00.914016982Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "       cell_id  drift_score  quality_avg  quality_min  quality_max  \\\n0      (1946,)        0.875     0.874160     0.734750     1.688068   \n1      (1945,)        0.875     0.881240     0.712539     1.069511   \n2      (1947,)        1.000     0.842714     0.679234     0.999486   \n3      (1941,)        0.875     0.852673     0.678700     1.311538   \n4      (1943,)        1.000     0.806085     0.669411     1.095661   \n...        ...          ...          ...          ...          ...   \n1038  (12482,)        0.875     0.868466     0.725107     1.062574   \n1039  (12483,)        0.875     0.883805     0.840871     0.929947   \n1040  (12481,)        0.875     0.965920     0.886776     1.042712   \n1041  (13323,)        0.875     0.981018     0.911628     1.053775   \n1042  (13322,)        0.875     0.939830     0.904408     0.990518   \n\n      quality_std  cum_reward_avg  cum_reward_max  cum_reward_std  \\\n0        0.056874   -3.587066e+06             -50    3.191874e+06   \n1        0.036131   -3.584984e+06             -45    3.210989e+06   \n2        0.047754   -1.135826e+06             -10    1.033637e+06   \n3        0.068895   -3.447562e+06             -50    3.098796e+06   \n4        0.088054   -3.405338e+06             -45    2.981054e+06   \n...           ...             ...             ...             ...   \n1038     0.031370   -3.961857e+05             -45    3.373165e+05   \n1039     0.020493   -9.898051e+04               5    9.285494e+04   \n1040     0.034750   -1.163850e+05             -50    1.039313e+05   \n1041     0.032089   -5.948250e+04             -45    5.296255e+04   \n1042     0.015661   -5.892000e+04             -45    5.264149e+04   \n\n      mom_reward_avg  mom_reward_min  mom_reward_max  mom_reward_std  \n0      -17734.276206          -34940             -50    10101.580818  \n1      -17866.888519          -35685             -45    10343.056816  \n2       -5546.775000           -9820             -10     3137.497803  \n3      -17337.090301          -34600             -50    10117.079323  \n4      -16600.342809          -32240             -45     9092.147583  \n...              ...             ...             ...             ...  \n1038    -5342.690476          -10220             -45     2780.442553  \n1039    -2863.457944           -5975               5     1811.103647  \n1040    -3215.140187           -6395             -50     1861.693343  \n1041    -2295.000000           -4545             -45     1324.990566  \n1042    -2280.197368           -4530             -45     1324.652015  \n\n[1043 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cell_id</th>\n      <th>drift_score</th>\n      <th>quality_avg</th>\n      <th>quality_min</th>\n      <th>quality_max</th>\n      <th>quality_std</th>\n      <th>cum_reward_avg</th>\n      <th>cum_reward_max</th>\n      <th>cum_reward_std</th>\n      <th>mom_reward_avg</th>\n      <th>mom_reward_min</th>\n      <th>mom_reward_max</th>\n      <th>mom_reward_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(1946,)</td>\n      <td>0.875</td>\n      <td>0.874160</td>\n      <td>0.734750</td>\n      <td>1.688068</td>\n      <td>0.056874</td>\n      <td>-3.587066e+06</td>\n      <td>-50</td>\n      <td>3.191874e+06</td>\n      <td>-17734.276206</td>\n      <td>-34940</td>\n      <td>-50</td>\n      <td>10101.580818</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(1945,)</td>\n      <td>0.875</td>\n      <td>0.881240</td>\n      <td>0.712539</td>\n      <td>1.069511</td>\n      <td>0.036131</td>\n      <td>-3.584984e+06</td>\n      <td>-45</td>\n      <td>3.210989e+06</td>\n      <td>-17866.888519</td>\n      <td>-35685</td>\n      <td>-45</td>\n      <td>10343.056816</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(1947,)</td>\n      <td>1.000</td>\n      <td>0.842714</td>\n      <td>0.679234</td>\n      <td>0.999486</td>\n      <td>0.047754</td>\n      <td>-1.135826e+06</td>\n      <td>-10</td>\n      <td>1.033637e+06</td>\n      <td>-5546.775000</td>\n      <td>-9820</td>\n      <td>-10</td>\n      <td>3137.497803</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(1941,)</td>\n      <td>0.875</td>\n      <td>0.852673</td>\n      <td>0.678700</td>\n      <td>1.311538</td>\n      <td>0.068895</td>\n      <td>-3.447562e+06</td>\n      <td>-50</td>\n      <td>3.098796e+06</td>\n      <td>-17337.090301</td>\n      <td>-34600</td>\n      <td>-50</td>\n      <td>10117.079323</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(1943,)</td>\n      <td>1.000</td>\n      <td>0.806085</td>\n      <td>0.669411</td>\n      <td>1.095661</td>\n      <td>0.088054</td>\n      <td>-3.405338e+06</td>\n      <td>-45</td>\n      <td>2.981054e+06</td>\n      <td>-16600.342809</td>\n      <td>-32240</td>\n      <td>-45</td>\n      <td>9092.147583</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1038</th>\n      <td>(12482,)</td>\n      <td>0.875</td>\n      <td>0.868466</td>\n      <td>0.725107</td>\n      <td>1.062574</td>\n      <td>0.031370</td>\n      <td>-3.961857e+05</td>\n      <td>-45</td>\n      <td>3.373165e+05</td>\n      <td>-5342.690476</td>\n      <td>-10220</td>\n      <td>-45</td>\n      <td>2780.442553</td>\n    </tr>\n    <tr>\n      <th>1039</th>\n      <td>(12483,)</td>\n      <td>0.875</td>\n      <td>0.883805</td>\n      <td>0.840871</td>\n      <td>0.929947</td>\n      <td>0.020493</td>\n      <td>-9.898051e+04</td>\n      <td>5</td>\n      <td>9.285494e+04</td>\n      <td>-2863.457944</td>\n      <td>-5975</td>\n      <td>5</td>\n      <td>1811.103647</td>\n    </tr>\n    <tr>\n      <th>1040</th>\n      <td>(12481,)</td>\n      <td>0.875</td>\n      <td>0.965920</td>\n      <td>0.886776</td>\n      <td>1.042712</td>\n      <td>0.034750</td>\n      <td>-1.163850e+05</td>\n      <td>-50</td>\n      <td>1.039313e+05</td>\n      <td>-3215.140187</td>\n      <td>-6395</td>\n      <td>-50</td>\n      <td>1861.693343</td>\n    </tr>\n    <tr>\n      <th>1041</th>\n      <td>(13323,)</td>\n      <td>0.875</td>\n      <td>0.981018</td>\n      <td>0.911628</td>\n      <td>1.053775</td>\n      <td>0.032089</td>\n      <td>-5.948250e+04</td>\n      <td>-45</td>\n      <td>5.296255e+04</td>\n      <td>-2295.000000</td>\n      <td>-4545</td>\n      <td>-45</td>\n      <td>1324.990566</td>\n    </tr>\n    <tr>\n      <th>1042</th>\n      <td>(13322,)</td>\n      <td>0.875</td>\n      <td>0.939830</td>\n      <td>0.904408</td>\n      <td>0.990518</td>\n      <td>0.015661</td>\n      <td>-5.892000e+04</td>\n      <td>-45</td>\n      <td>5.264149e+04</td>\n      <td>-2280.197368</td>\n      <td>-4530</td>\n      <td>-45</td>\n      <td>1324.652015</td>\n    </tr>\n  </tbody>\n</table>\n<p>1043 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T12:29:01.388782215Z",
     "start_time": "2023-09-05T12:29:01.356854579Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                drift_score  quality_avg  quality_min  quality_max  \\\ndrift_score        1.000000    -0.252896    -0.098583    -0.039432   \nquality_avg       -0.252896     1.000000     0.502643     0.333520   \nquality_min       -0.098583     0.502643     1.000000     0.119505   \nquality_max       -0.039432     0.333520     0.119505     1.000000   \nquality_std       -0.127550     0.159484    -0.134206     0.468174   \ncum_reward_avg     0.006945     0.045978     0.070530    -0.152249   \ncum_reward_max     0.068895    -0.038443    -0.045746    -0.073236   \ncum_reward_std    -0.021761     0.009329    -0.026577     0.173904   \nmom_reward_avg     0.066041    -0.147332    -0.088060    -0.215231   \nmom_reward_min     0.083738    -0.238948    -0.172310    -0.239303   \nmom_reward_max     0.066402    -0.042868    -0.047839    -0.114423   \nmom_reward_std    -0.093436     0.259073     0.182302     0.240701   \n\n                quality_std  cum_reward_avg  cum_reward_max  cum_reward_std  \\\ndrift_score       -0.127550        0.006945        0.068895       -0.021761   \nquality_avg        0.159484        0.045978       -0.038443        0.009329   \nquality_min       -0.134206        0.070530       -0.045746       -0.026577   \nquality_max        0.468174       -0.152249       -0.073236        0.173904   \nquality_std        1.000000       -0.085979       -0.064057        0.063141   \ncum_reward_avg    -0.085979        1.000000        0.171343       -0.990619   \ncum_reward_max    -0.064057        0.171343        1.000000       -0.136974   \ncum_reward_std     0.063141       -0.990619       -0.136974        1.000000   \nmom_reward_avg    -0.068361        0.932597        0.164816       -0.960482   \nmom_reward_min    -0.014295        0.820249        0.088091       -0.882851   \nmom_reward_max    -0.175647        0.390343        0.643997       -0.335615   \nmom_reward_std     0.007254       -0.802359       -0.063820        0.870986   \n\n                mom_reward_avg  mom_reward_min  mom_reward_max  mom_reward_std  \ndrift_score           0.066041        0.083738        0.066402       -0.093436  \nquality_avg          -0.147332       -0.238948       -0.042868        0.259073  \nquality_min          -0.088060       -0.172310       -0.047839        0.182302  \nquality_max          -0.215231       -0.239303       -0.114423        0.240701  \nquality_std          -0.068361       -0.014295       -0.175647        0.007254  \ncum_reward_avg        0.932597        0.820249        0.390343       -0.802359  \ncum_reward_max        0.164816        0.088091        0.643997       -0.063820  \ncum_reward_std       -0.960482       -0.882851       -0.335615        0.870986  \nmom_reward_avg        1.000000        0.957747        0.382207       -0.948690  \nmom_reward_min        0.957747        1.000000        0.236172       -0.995768  \nmom_reward_max        0.382207        0.236172        1.000000       -0.205588  \nmom_reward_std       -0.948690       -0.995768       -0.205588        1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>drift_score</th>\n      <th>quality_avg</th>\n      <th>quality_min</th>\n      <th>quality_max</th>\n      <th>quality_std</th>\n      <th>cum_reward_avg</th>\n      <th>cum_reward_max</th>\n      <th>cum_reward_std</th>\n      <th>mom_reward_avg</th>\n      <th>mom_reward_min</th>\n      <th>mom_reward_max</th>\n      <th>mom_reward_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>drift_score</th>\n      <td>1.000000</td>\n      <td>-0.252896</td>\n      <td>-0.098583</td>\n      <td>-0.039432</td>\n      <td>-0.127550</td>\n      <td>0.006945</td>\n      <td>0.068895</td>\n      <td>-0.021761</td>\n      <td>0.066041</td>\n      <td>0.083738</td>\n      <td>0.066402</td>\n      <td>-0.093436</td>\n    </tr>\n    <tr>\n      <th>quality_avg</th>\n      <td>-0.252896</td>\n      <td>1.000000</td>\n      <td>0.502643</td>\n      <td>0.333520</td>\n      <td>0.159484</td>\n      <td>0.045978</td>\n      <td>-0.038443</td>\n      <td>0.009329</td>\n      <td>-0.147332</td>\n      <td>-0.238948</td>\n      <td>-0.042868</td>\n      <td>0.259073</td>\n    </tr>\n    <tr>\n      <th>quality_min</th>\n      <td>-0.098583</td>\n      <td>0.502643</td>\n      <td>1.000000</td>\n      <td>0.119505</td>\n      <td>-0.134206</td>\n      <td>0.070530</td>\n      <td>-0.045746</td>\n      <td>-0.026577</td>\n      <td>-0.088060</td>\n      <td>-0.172310</td>\n      <td>-0.047839</td>\n      <td>0.182302</td>\n    </tr>\n    <tr>\n      <th>quality_max</th>\n      <td>-0.039432</td>\n      <td>0.333520</td>\n      <td>0.119505</td>\n      <td>1.000000</td>\n      <td>0.468174</td>\n      <td>-0.152249</td>\n      <td>-0.073236</td>\n      <td>0.173904</td>\n      <td>-0.215231</td>\n      <td>-0.239303</td>\n      <td>-0.114423</td>\n      <td>0.240701</td>\n    </tr>\n    <tr>\n      <th>quality_std</th>\n      <td>-0.127550</td>\n      <td>0.159484</td>\n      <td>-0.134206</td>\n      <td>0.468174</td>\n      <td>1.000000</td>\n      <td>-0.085979</td>\n      <td>-0.064057</td>\n      <td>0.063141</td>\n      <td>-0.068361</td>\n      <td>-0.014295</td>\n      <td>-0.175647</td>\n      <td>0.007254</td>\n    </tr>\n    <tr>\n      <th>cum_reward_avg</th>\n      <td>0.006945</td>\n      <td>0.045978</td>\n      <td>0.070530</td>\n      <td>-0.152249</td>\n      <td>-0.085979</td>\n      <td>1.000000</td>\n      <td>0.171343</td>\n      <td>-0.990619</td>\n      <td>0.932597</td>\n      <td>0.820249</td>\n      <td>0.390343</td>\n      <td>-0.802359</td>\n    </tr>\n    <tr>\n      <th>cum_reward_max</th>\n      <td>0.068895</td>\n      <td>-0.038443</td>\n      <td>-0.045746</td>\n      <td>-0.073236</td>\n      <td>-0.064057</td>\n      <td>0.171343</td>\n      <td>1.000000</td>\n      <td>-0.136974</td>\n      <td>0.164816</td>\n      <td>0.088091</td>\n      <td>0.643997</td>\n      <td>-0.063820</td>\n    </tr>\n    <tr>\n      <th>cum_reward_std</th>\n      <td>-0.021761</td>\n      <td>0.009329</td>\n      <td>-0.026577</td>\n      <td>0.173904</td>\n      <td>0.063141</td>\n      <td>-0.990619</td>\n      <td>-0.136974</td>\n      <td>1.000000</td>\n      <td>-0.960482</td>\n      <td>-0.882851</td>\n      <td>-0.335615</td>\n      <td>0.870986</td>\n    </tr>\n    <tr>\n      <th>mom_reward_avg</th>\n      <td>0.066041</td>\n      <td>-0.147332</td>\n      <td>-0.088060</td>\n      <td>-0.215231</td>\n      <td>-0.068361</td>\n      <td>0.932597</td>\n      <td>0.164816</td>\n      <td>-0.960482</td>\n      <td>1.000000</td>\n      <td>0.957747</td>\n      <td>0.382207</td>\n      <td>-0.948690</td>\n    </tr>\n    <tr>\n      <th>mom_reward_min</th>\n      <td>0.083738</td>\n      <td>-0.238948</td>\n      <td>-0.172310</td>\n      <td>-0.239303</td>\n      <td>-0.014295</td>\n      <td>0.820249</td>\n      <td>0.088091</td>\n      <td>-0.882851</td>\n      <td>0.957747</td>\n      <td>1.000000</td>\n      <td>0.236172</td>\n      <td>-0.995768</td>\n    </tr>\n    <tr>\n      <th>mom_reward_max</th>\n      <td>0.066402</td>\n      <td>-0.042868</td>\n      <td>-0.047839</td>\n      <td>-0.114423</td>\n      <td>-0.175647</td>\n      <td>0.390343</td>\n      <td>0.643997</td>\n      <td>-0.335615</td>\n      <td>0.382207</td>\n      <td>0.236172</td>\n      <td>1.000000</td>\n      <td>-0.205588</td>\n    </tr>\n    <tr>\n      <th>mom_reward_std</th>\n      <td>-0.093436</td>\n      <td>0.259073</td>\n      <td>0.182302</td>\n      <td>0.240701</td>\n      <td>0.007254</td>\n      <td>-0.802359</td>\n      <td>-0.063820</td>\n      <td>0.870986</td>\n      <td>-0.948690</td>\n      <td>-0.995768</td>\n      <td>-0.205588</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.columns[1:]].corr()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T12:29:01.820162893Z",
     "start_time": "2023-09-05T12:29:01.683310199Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "                drift_score  quality_avg  quality_min  quality_max  \\\ndrift_score        1.000000    -0.222758    -0.091771    -0.029052   \nquality_avg       -0.222758     1.000000     0.369532     0.226132   \nquality_min       -0.091771     0.369532     1.000000     0.108647   \nquality_max       -0.029052     0.226132     0.108647     1.000000   \nquality_std       -0.115285     0.029151    -0.098588     0.245643   \ncum_reward_avg     0.072701    -0.063192    -0.091750    -0.148184   \ncum_reward_max     0.045894    -0.003026     0.017899    -0.051916   \ncum_reward_std    -0.073499     0.080686     0.099998     0.153613   \nmom_reward_avg     0.083750    -0.144342    -0.152579    -0.176647   \nmom_reward_min     0.090964    -0.197440    -0.193956    -0.184298   \nmom_reward_max     0.051647    -0.006468     0.013766    -0.048123   \nmom_reward_std    -0.100316     0.203410     0.190701     0.182747   \n\n                quality_std  cum_reward_avg  cum_reward_max  cum_reward_std  \\\ndrift_score       -0.115285        0.072701        0.045894       -0.073499   \nquality_avg        0.029151       -0.063192       -0.003026        0.080686   \nquality_min       -0.098588       -0.091750        0.017899        0.099998   \nquality_max        0.245643       -0.148184       -0.051916        0.153613   \nquality_std        1.000000       -0.014785       -0.141789        0.008767   \ncum_reward_avg    -0.014785        1.000000        0.018777       -0.951919   \ncum_reward_max    -0.141789        0.018777        1.000000       -0.003903   \ncum_reward_std     0.008767       -0.951919       -0.003903        1.000000   \nmom_reward_avg    -0.001689        0.858744       -0.004915       -0.893549   \nmom_reward_min     0.017910        0.737975       -0.033414       -0.776462   \nmom_reward_max    -0.141768        0.023881        0.991089       -0.008326   \nmom_reward_std    -0.020737       -0.743357        0.042257        0.787545   \n\n                mom_reward_avg  mom_reward_min  mom_reward_max  mom_reward_std  \ndrift_score           0.083750        0.090964        0.051647       -0.100316  \nquality_avg          -0.144342       -0.197440       -0.006468        0.203410  \nquality_min          -0.152579       -0.193956        0.013766        0.190701  \nquality_max          -0.176647       -0.184298       -0.048123        0.182747  \nquality_std          -0.001689        0.017910       -0.141768       -0.020737  \ncum_reward_avg        0.858744        0.737975        0.023881       -0.743357  \ncum_reward_max       -0.004915       -0.033414        0.991089        0.042257  \ncum_reward_std       -0.893549       -0.776462       -0.008326        0.787545  \nmom_reward_avg        1.000000        0.864664        0.000553       -0.873894  \nmom_reward_min        0.864664        1.000000       -0.029540       -0.941438  \nmom_reward_max        0.000553       -0.029540        1.000000        0.038623  \nmom_reward_std       -0.873894       -0.941438        0.038623        1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>drift_score</th>\n      <th>quality_avg</th>\n      <th>quality_min</th>\n      <th>quality_max</th>\n      <th>quality_std</th>\n      <th>cum_reward_avg</th>\n      <th>cum_reward_max</th>\n      <th>cum_reward_std</th>\n      <th>mom_reward_avg</th>\n      <th>mom_reward_min</th>\n      <th>mom_reward_max</th>\n      <th>mom_reward_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>drift_score</th>\n      <td>1.000000</td>\n      <td>-0.222758</td>\n      <td>-0.091771</td>\n      <td>-0.029052</td>\n      <td>-0.115285</td>\n      <td>0.072701</td>\n      <td>0.045894</td>\n      <td>-0.073499</td>\n      <td>0.083750</td>\n      <td>0.090964</td>\n      <td>0.051647</td>\n      <td>-0.100316</td>\n    </tr>\n    <tr>\n      <th>quality_avg</th>\n      <td>-0.222758</td>\n      <td>1.000000</td>\n      <td>0.369532</td>\n      <td>0.226132</td>\n      <td>0.029151</td>\n      <td>-0.063192</td>\n      <td>-0.003026</td>\n      <td>0.080686</td>\n      <td>-0.144342</td>\n      <td>-0.197440</td>\n      <td>-0.006468</td>\n      <td>0.203410</td>\n    </tr>\n    <tr>\n      <th>quality_min</th>\n      <td>-0.091771</td>\n      <td>0.369532</td>\n      <td>1.000000</td>\n      <td>0.108647</td>\n      <td>-0.098588</td>\n      <td>-0.091750</td>\n      <td>0.017899</td>\n      <td>0.099998</td>\n      <td>-0.152579</td>\n      <td>-0.193956</td>\n      <td>0.013766</td>\n      <td>0.190701</td>\n    </tr>\n    <tr>\n      <th>quality_max</th>\n      <td>-0.029052</td>\n      <td>0.226132</td>\n      <td>0.108647</td>\n      <td>1.000000</td>\n      <td>0.245643</td>\n      <td>-0.148184</td>\n      <td>-0.051916</td>\n      <td>0.153613</td>\n      <td>-0.176647</td>\n      <td>-0.184298</td>\n      <td>-0.048123</td>\n      <td>0.182747</td>\n    </tr>\n    <tr>\n      <th>quality_std</th>\n      <td>-0.115285</td>\n      <td>0.029151</td>\n      <td>-0.098588</td>\n      <td>0.245643</td>\n      <td>1.000000</td>\n      <td>-0.014785</td>\n      <td>-0.141789</td>\n      <td>0.008767</td>\n      <td>-0.001689</td>\n      <td>0.017910</td>\n      <td>-0.141768</td>\n      <td>-0.020737</td>\n    </tr>\n    <tr>\n      <th>cum_reward_avg</th>\n      <td>0.072701</td>\n      <td>-0.063192</td>\n      <td>-0.091750</td>\n      <td>-0.148184</td>\n      <td>-0.014785</td>\n      <td>1.000000</td>\n      <td>0.018777</td>\n      <td>-0.951919</td>\n      <td>0.858744</td>\n      <td>0.737975</td>\n      <td>0.023881</td>\n      <td>-0.743357</td>\n    </tr>\n    <tr>\n      <th>cum_reward_max</th>\n      <td>0.045894</td>\n      <td>-0.003026</td>\n      <td>0.017899</td>\n      <td>-0.051916</td>\n      <td>-0.141789</td>\n      <td>0.018777</td>\n      <td>1.000000</td>\n      <td>-0.003903</td>\n      <td>-0.004915</td>\n      <td>-0.033414</td>\n      <td>0.991089</td>\n      <td>0.042257</td>\n    </tr>\n    <tr>\n      <th>cum_reward_std</th>\n      <td>-0.073499</td>\n      <td>0.080686</td>\n      <td>0.099998</td>\n      <td>0.153613</td>\n      <td>0.008767</td>\n      <td>-0.951919</td>\n      <td>-0.003903</td>\n      <td>1.000000</td>\n      <td>-0.893549</td>\n      <td>-0.776462</td>\n      <td>-0.008326</td>\n      <td>0.787545</td>\n    </tr>\n    <tr>\n      <th>mom_reward_avg</th>\n      <td>0.083750</td>\n      <td>-0.144342</td>\n      <td>-0.152579</td>\n      <td>-0.176647</td>\n      <td>-0.001689</td>\n      <td>0.858744</td>\n      <td>-0.004915</td>\n      <td>-0.893549</td>\n      <td>1.000000</td>\n      <td>0.864664</td>\n      <td>0.000553</td>\n      <td>-0.873894</td>\n    </tr>\n    <tr>\n      <th>mom_reward_min</th>\n      <td>0.090964</td>\n      <td>-0.197440</td>\n      <td>-0.193956</td>\n      <td>-0.184298</td>\n      <td>0.017910</td>\n      <td>0.737975</td>\n      <td>-0.033414</td>\n      <td>-0.776462</td>\n      <td>0.864664</td>\n      <td>1.000000</td>\n      <td>-0.029540</td>\n      <td>-0.941438</td>\n    </tr>\n    <tr>\n      <th>mom_reward_max</th>\n      <td>0.051647</td>\n      <td>-0.006468</td>\n      <td>0.013766</td>\n      <td>-0.048123</td>\n      <td>-0.141768</td>\n      <td>0.023881</td>\n      <td>0.991089</td>\n      <td>-0.008326</td>\n      <td>0.000553</td>\n      <td>-0.029540</td>\n      <td>1.000000</td>\n      <td>0.038623</td>\n    </tr>\n    <tr>\n      <th>mom_reward_std</th>\n      <td>-0.100316</td>\n      <td>0.203410</td>\n      <td>0.190701</td>\n      <td>0.182747</td>\n      <td>-0.020737</td>\n      <td>-0.743357</td>\n      <td>0.042257</td>\n      <td>0.787545</td>\n      <td>-0.873894</td>\n      <td>-0.941438</td>\n      <td>0.038623</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.columns[1:]].corr(method='kendall')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T12:50:09.740348411Z",
     "start_time": "2023-09-05T12:50:09.657774354Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "                drift_score  quality_avg  quality_min  quality_max  \\\ndrift_score        1.000000    -0.273376    -0.112515    -0.035694   \nquality_avg       -0.273376     1.000000     0.527301     0.333326   \nquality_min       -0.112515     0.527301     1.000000     0.159504   \nquality_max       -0.035694     0.333326     0.159504     1.000000   \nquality_std       -0.141639     0.035460    -0.143087     0.356822   \ncum_reward_avg     0.089374    -0.087325    -0.132457    -0.218206   \ncum_reward_max     0.048655    -0.006718     0.021839    -0.066568   \ncum_reward_std    -0.090309     0.112539     0.143934     0.227353   \nmom_reward_avg     0.102738    -0.210416    -0.220827    -0.261694   \nmom_reward_min     0.111457    -0.295772    -0.283947    -0.273858   \nmom_reward_max     0.054876    -0.011162     0.016713    -0.061734   \nmom_reward_std    -0.122876     0.305211     0.280873     0.271981   \n\n                quality_std  cum_reward_avg  cum_reward_max  cum_reward_std  \\\ndrift_score       -0.141639        0.089374        0.048655       -0.090309   \nquality_avg        0.035460       -0.087325       -0.006718        0.112539   \nquality_min       -0.143087       -0.132457        0.021839        0.143934   \nquality_max        0.356822       -0.218206       -0.066568        0.227353   \nquality_std        1.000000       -0.023141       -0.182319        0.014738   \ncum_reward_avg    -0.023141        1.000000        0.026761       -0.995112   \ncum_reward_max    -0.182319        0.026761        1.000000       -0.007330   \ncum_reward_std     0.014738       -0.995112       -0.007330        1.000000   \nmom_reward_avg    -0.004675        0.967544       -0.002111       -0.979258   \nmom_reward_min     0.026537        0.908117       -0.040000       -0.929143   \nmom_reward_max    -0.182486        0.033117        0.993497       -0.012881   \nmom_reward_std    -0.030574       -0.908042        0.051562        0.930875   \n\n                mom_reward_avg  mom_reward_min  mom_reward_max  mom_reward_std  \ndrift_score           0.102738        0.111457        0.054876       -0.122876  \nquality_avg          -0.210416       -0.295772       -0.011162        0.305211  \nquality_min          -0.220827       -0.283947        0.016713        0.280873  \nquality_max          -0.261694       -0.273858       -0.061734        0.271981  \nquality_std          -0.004675        0.026537       -0.182486       -0.030574  \ncum_reward_avg        0.967544        0.908117        0.033117       -0.908042  \ncum_reward_max       -0.002111       -0.040000        0.993497        0.051562  \ncum_reward_std       -0.979258       -0.929143       -0.012881        0.930875  \nmom_reward_avg        1.000000        0.972041        0.004592       -0.971656  \nmom_reward_min        0.972041        1.000000       -0.035342       -0.994058  \nmom_reward_max        0.004592       -0.035342        1.000000        0.047299  \nmom_reward_std       -0.971656       -0.994058        0.047299        1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>drift_score</th>\n      <th>quality_avg</th>\n      <th>quality_min</th>\n      <th>quality_max</th>\n      <th>quality_std</th>\n      <th>cum_reward_avg</th>\n      <th>cum_reward_max</th>\n      <th>cum_reward_std</th>\n      <th>mom_reward_avg</th>\n      <th>mom_reward_min</th>\n      <th>mom_reward_max</th>\n      <th>mom_reward_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>drift_score</th>\n      <td>1.000000</td>\n      <td>-0.273376</td>\n      <td>-0.112515</td>\n      <td>-0.035694</td>\n      <td>-0.141639</td>\n      <td>0.089374</td>\n      <td>0.048655</td>\n      <td>-0.090309</td>\n      <td>0.102738</td>\n      <td>0.111457</td>\n      <td>0.054876</td>\n      <td>-0.122876</td>\n    </tr>\n    <tr>\n      <th>quality_avg</th>\n      <td>-0.273376</td>\n      <td>1.000000</td>\n      <td>0.527301</td>\n      <td>0.333326</td>\n      <td>0.035460</td>\n      <td>-0.087325</td>\n      <td>-0.006718</td>\n      <td>0.112539</td>\n      <td>-0.210416</td>\n      <td>-0.295772</td>\n      <td>-0.011162</td>\n      <td>0.305211</td>\n    </tr>\n    <tr>\n      <th>quality_min</th>\n      <td>-0.112515</td>\n      <td>0.527301</td>\n      <td>1.000000</td>\n      <td>0.159504</td>\n      <td>-0.143087</td>\n      <td>-0.132457</td>\n      <td>0.021839</td>\n      <td>0.143934</td>\n      <td>-0.220827</td>\n      <td>-0.283947</td>\n      <td>0.016713</td>\n      <td>0.280873</td>\n    </tr>\n    <tr>\n      <th>quality_max</th>\n      <td>-0.035694</td>\n      <td>0.333326</td>\n      <td>0.159504</td>\n      <td>1.000000</td>\n      <td>0.356822</td>\n      <td>-0.218206</td>\n      <td>-0.066568</td>\n      <td>0.227353</td>\n      <td>-0.261694</td>\n      <td>-0.273858</td>\n      <td>-0.061734</td>\n      <td>0.271981</td>\n    </tr>\n    <tr>\n      <th>quality_std</th>\n      <td>-0.141639</td>\n      <td>0.035460</td>\n      <td>-0.143087</td>\n      <td>0.356822</td>\n      <td>1.000000</td>\n      <td>-0.023141</td>\n      <td>-0.182319</td>\n      <td>0.014738</td>\n      <td>-0.004675</td>\n      <td>0.026537</td>\n      <td>-0.182486</td>\n      <td>-0.030574</td>\n    </tr>\n    <tr>\n      <th>cum_reward_avg</th>\n      <td>0.089374</td>\n      <td>-0.087325</td>\n      <td>-0.132457</td>\n      <td>-0.218206</td>\n      <td>-0.023141</td>\n      <td>1.000000</td>\n      <td>0.026761</td>\n      <td>-0.995112</td>\n      <td>0.967544</td>\n      <td>0.908117</td>\n      <td>0.033117</td>\n      <td>-0.908042</td>\n    </tr>\n    <tr>\n      <th>cum_reward_max</th>\n      <td>0.048655</td>\n      <td>-0.006718</td>\n      <td>0.021839</td>\n      <td>-0.066568</td>\n      <td>-0.182319</td>\n      <td>0.026761</td>\n      <td>1.000000</td>\n      <td>-0.007330</td>\n      <td>-0.002111</td>\n      <td>-0.040000</td>\n      <td>0.993497</td>\n      <td>0.051562</td>\n    </tr>\n    <tr>\n      <th>cum_reward_std</th>\n      <td>-0.090309</td>\n      <td>0.112539</td>\n      <td>0.143934</td>\n      <td>0.227353</td>\n      <td>0.014738</td>\n      <td>-0.995112</td>\n      <td>-0.007330</td>\n      <td>1.000000</td>\n      <td>-0.979258</td>\n      <td>-0.929143</td>\n      <td>-0.012881</td>\n      <td>0.930875</td>\n    </tr>\n    <tr>\n      <th>mom_reward_avg</th>\n      <td>0.102738</td>\n      <td>-0.210416</td>\n      <td>-0.220827</td>\n      <td>-0.261694</td>\n      <td>-0.004675</td>\n      <td>0.967544</td>\n      <td>-0.002111</td>\n      <td>-0.979258</td>\n      <td>1.000000</td>\n      <td>0.972041</td>\n      <td>0.004592</td>\n      <td>-0.971656</td>\n    </tr>\n    <tr>\n      <th>mom_reward_min</th>\n      <td>0.111457</td>\n      <td>-0.295772</td>\n      <td>-0.283947</td>\n      <td>-0.273858</td>\n      <td>0.026537</td>\n      <td>0.908117</td>\n      <td>-0.040000</td>\n      <td>-0.929143</td>\n      <td>0.972041</td>\n      <td>1.000000</td>\n      <td>-0.035342</td>\n      <td>-0.994058</td>\n    </tr>\n    <tr>\n      <th>mom_reward_max</th>\n      <td>0.054876</td>\n      <td>-0.011162</td>\n      <td>0.016713</td>\n      <td>-0.061734</td>\n      <td>-0.182486</td>\n      <td>0.033117</td>\n      <td>0.993497</td>\n      <td>-0.012881</td>\n      <td>0.004592</td>\n      <td>-0.035342</td>\n      <td>1.000000</td>\n      <td>0.047299</td>\n    </tr>\n    <tr>\n      <th>mom_reward_std</th>\n      <td>-0.122876</td>\n      <td>0.305211</td>\n      <td>0.280873</td>\n      <td>0.271981</td>\n      <td>-0.030574</td>\n      <td>-0.908042</td>\n      <td>0.051562</td>\n      <td>0.930875</td>\n      <td>-0.971656</td>\n      <td>-0.994058</td>\n      <td>0.047299</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.columns[1:]].corr(method='spearman')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T12:51:07.917949434Z",
     "start_time": "2023-09-05T12:51:07.863669882Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "       drift_score  quality_avg  quality_min  quality_max  quality_std  \\\ncount  1043.000000  1043.000000  1043.000000  1043.000000  1043.000000   \nmean      0.898011     0.860945     0.711063     1.258105     0.057515   \nstd       0.049690     0.055507     0.035201     0.225152     0.016506   \nmin       0.750000     0.718305     0.607482     0.867746     0.015185   \n25%       0.875000     0.821165     0.688939     1.094380     0.045872   \n50%       0.875000     0.854715     0.710457     1.209379     0.055981   \n75%       0.875000     0.898882     0.731056     1.373682     0.067125   \nmax       1.000000     1.037022     0.911628     3.080180     0.178629   \n\n       cum_reward_avg  cum_reward_max  cum_reward_std  mom_reward_avg  \\\ncount    1.043000e+03     1043.000000    1.043000e+03     1043.000000   \nmean    -2.911674e+06      -31.299137    2.548311e+06   -14916.982646   \nstd      7.938138e+05      228.456211    7.136710e+05     3429.972718   \nmin     -3.587066e+06      -60.000000    5.264149e+04   -17866.888519   \n25%     -3.436793e+06      -50.000000    2.317062e+06   -17510.304231   \n50%     -3.302644e+06      -45.000000    2.922087e+06   -16623.737288   \n75%     -2.855031e+06      -45.000000    3.069585e+06   -12960.904458   \nmax     -5.892000e+04     5680.000000    3.210989e+06    -1449.232143   \n\n       mom_reward_min  mom_reward_max  mom_reward_std  \ncount     1043.000000     1043.000000     1043.000000  \nmean    -28383.767977      -46.188878     8182.108460  \nstd       7613.847676       17.025041     2259.314345  \nmin     -35685.000000      -60.000000      934.315267  \n25%     -34815.000000      -50.000000     6326.187334  \n50%     -32055.000000      -45.000000     9286.716257  \n75%     -23415.000000      -45.000000    10079.644416  \nmax      -3060.000000      155.000000    10343.056816  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>drift_score</th>\n      <th>quality_avg</th>\n      <th>quality_min</th>\n      <th>quality_max</th>\n      <th>quality_std</th>\n      <th>cum_reward_avg</th>\n      <th>cum_reward_max</th>\n      <th>cum_reward_std</th>\n      <th>mom_reward_avg</th>\n      <th>mom_reward_min</th>\n      <th>mom_reward_max</th>\n      <th>mom_reward_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1043.000000</td>\n      <td>1043.000000</td>\n      <td>1043.000000</td>\n      <td>1043.000000</td>\n      <td>1043.000000</td>\n      <td>1.043000e+03</td>\n      <td>1043.000000</td>\n      <td>1.043000e+03</td>\n      <td>1043.000000</td>\n      <td>1043.000000</td>\n      <td>1043.000000</td>\n      <td>1043.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.898011</td>\n      <td>0.860945</td>\n      <td>0.711063</td>\n      <td>1.258105</td>\n      <td>0.057515</td>\n      <td>-2.911674e+06</td>\n      <td>-31.299137</td>\n      <td>2.548311e+06</td>\n      <td>-14916.982646</td>\n      <td>-28383.767977</td>\n      <td>-46.188878</td>\n      <td>8182.108460</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.049690</td>\n      <td>0.055507</td>\n      <td>0.035201</td>\n      <td>0.225152</td>\n      <td>0.016506</td>\n      <td>7.938138e+05</td>\n      <td>228.456211</td>\n      <td>7.136710e+05</td>\n      <td>3429.972718</td>\n      <td>7613.847676</td>\n      <td>17.025041</td>\n      <td>2259.314345</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.750000</td>\n      <td>0.718305</td>\n      <td>0.607482</td>\n      <td>0.867746</td>\n      <td>0.015185</td>\n      <td>-3.587066e+06</td>\n      <td>-60.000000</td>\n      <td>5.264149e+04</td>\n      <td>-17866.888519</td>\n      <td>-35685.000000</td>\n      <td>-60.000000</td>\n      <td>934.315267</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.875000</td>\n      <td>0.821165</td>\n      <td>0.688939</td>\n      <td>1.094380</td>\n      <td>0.045872</td>\n      <td>-3.436793e+06</td>\n      <td>-50.000000</td>\n      <td>2.317062e+06</td>\n      <td>-17510.304231</td>\n      <td>-34815.000000</td>\n      <td>-50.000000</td>\n      <td>6326.187334</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.875000</td>\n      <td>0.854715</td>\n      <td>0.710457</td>\n      <td>1.209379</td>\n      <td>0.055981</td>\n      <td>-3.302644e+06</td>\n      <td>-45.000000</td>\n      <td>2.922087e+06</td>\n      <td>-16623.737288</td>\n      <td>-32055.000000</td>\n      <td>-45.000000</td>\n      <td>9286.716257</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.875000</td>\n      <td>0.898882</td>\n      <td>0.731056</td>\n      <td>1.373682</td>\n      <td>0.067125</td>\n      <td>-2.855031e+06</td>\n      <td>-45.000000</td>\n      <td>3.069585e+06</td>\n      <td>-12960.904458</td>\n      <td>-23415.000000</td>\n      <td>-45.000000</td>\n      <td>10079.644416</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.037022</td>\n      <td>0.911628</td>\n      <td>3.080180</td>\n      <td>0.178629</td>\n      <td>-5.892000e+04</td>\n      <td>5680.000000</td>\n      <td>3.210989e+06</td>\n      <td>-1449.232143</td>\n      <td>-3060.000000</td>\n      <td>155.000000</td>\n      <td>10343.056816</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T13:18:48.355840471Z",
     "start_time": "2023-09-05T13:18:48.298124249Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "       cell_id  drift_score  quality_avg  quality_min  quality_max  \\\n7     (13312,)        1.000     0.827806     0.683533     1.014011   \n8     (13311,)        1.000     0.766681     0.637207     1.072541   \n15    (22975,)        0.875     0.851060     0.708378     0.965337   \n43    (24233,)        1.000     0.779225     0.680422     1.389400   \n102    (9737,)        0.875     0.836526     0.688055     1.260287   \n192   (42857,)        0.875     0.901327     0.631919     1.170445   \n221    (8916,)        0.875     0.868850     0.690507     0.966925   \n248   (42856,)        0.875     0.925625     0.667989     1.060651   \n262   (41872,)        0.875     0.802087     0.709027     1.287416   \n294   (22971,)        1.000     0.791741     0.703038     1.269978   \n343    (8915,)        0.875     0.867354     0.694822     1.047998   \n407   (26191,)        0.875     0.911956     0.713553     1.094354   \n454   (10942,)        0.875     0.771474     0.656311     1.059600   \n487    (9442,)        0.875     0.816025     0.687247     1.143174   \n497     (723,)        0.875     0.721824     0.645863     1.071824   \n540    (7907,)        0.875     0.854747     0.700377     1.025181   \n681   (24692,)        0.875     0.888115     0.738502     1.207841   \n696     (756,)        0.875     0.816620     0.680187     1.133890   \n697     (755,)        1.000     0.773461     0.664145     1.042994   \n764    (7905,)        1.000     0.892627     0.729374     1.393866   \n784    (1914,)        1.000     0.777415     0.667302     1.420806   \n825    (3316,)        0.875     0.866045     0.681269     1.256254   \n843    (8067,)        0.875     0.871227     0.699260     1.060002   \n873    (8095,)        0.875     0.910326     0.728073     1.109251   \n874    (8096,)        0.875     0.897001     0.680304     1.476828   \n879    (8475,)        0.875     0.852101     0.715749     1.066042   \n999   (13315,)        1.000     0.782756     0.683124     0.905337   \n1000  (13317,)        1.000     0.811469     0.688337     0.902784   \n1001  (13316,)        1.000     0.800225     0.674919     1.047584   \n1012   (3336,)        1.000     0.848581     0.724462     1.063296   \n1013   (8926,)        0.875     0.852417     0.719747     1.170471   \n1025  (51357,)        0.875     0.848602     0.711222     0.960383   \n1028   (8641,)        1.000     0.859705     0.737558     1.309134   \n1031   (8645,)        0.875     0.913622     0.696276     1.142639   \n1032   (8647,)        0.875     0.904285     0.707715     1.134465   \n1039  (12483,)        0.875     0.883805     0.840871     0.929947   \n\n      quality_std  cum_reward_avg  cum_reward_max  cum_reward_std  \\\n7        0.051522   -1.488446e+06            5680    1.681490e+06   \n8        0.050251   -5.236529e+05              15    4.493878e+05   \n15       0.028175   -5.601129e+05             760    5.161057e+05   \n43       0.045879   -2.962463e+06              95    2.776694e+06   \n102      0.039131   -4.723727e+05             310    4.581045e+05   \n192      0.036514   -1.261592e+06              15    1.248601e+06   \n221      0.034120   -1.782831e+06              30    1.786634e+06   \n248      0.031276   -2.937212e+06               5    2.752871e+06   \n262      0.055670   -3.419002e+06               5    3.045949e+06   \n294      0.038279   -3.302312e+06               5    2.894209e+06   \n343      0.034472   -1.661120e+06             620    1.714007e+06   \n407      0.027854   -3.406125e+06               5    3.047013e+06   \n454      0.066389   -5.684150e+05              15    5.108068e+05   \n487      0.068671   -1.604065e+06               5    1.236551e+06   \n497      0.033284   -5.634072e+05              15    5.055907e+05   \n540      0.035920   -6.343403e+05             205    5.750568e+05   \n681      0.083353   -3.379557e+06              15    3.038718e+06   \n696      0.037189   -6.290347e+05              35    5.599607e+05   \n697      0.041261   -7.507052e+05            3095    9.750655e+05   \n764      0.043907   -1.623378e+06              90    1.829413e+06   \n784      0.047290   -3.308313e+06               5    2.954363e+06   \n825      0.049204   -1.507354e+06             185    1.563316e+06   \n843      0.030143   -1.849260e+06            2685    2.007034e+06   \n873      0.042007   -1.258608e+06              95    1.238586e+06   \n874      0.056152   -2.591923e+06              45    2.435863e+06   \n879      0.037450   -7.254497e+05             740    7.709472e+05   \n999      0.027435   -2.334333e+05               5    2.093858e+05   \n1000     0.027808   -8.332817e+05              95    7.550594e+05   \n1001     0.045738   -2.197884e+05             185    2.051258e+05   \n1012     0.058009   -3.053709e+05              15    3.066482e+05   \n1013     0.065038   -3.803507e+05              15    3.670664e+05   \n1025     0.070595   -1.632883e+05            1460    1.921173e+05   \n1028     0.056698   -6.352608e+05              10    5.787370e+05   \n1031     0.039373   -3.489248e+05               5    2.982530e+05   \n1032     0.042725   -1.286449e+05              15    1.204264e+05   \n1039     0.020493   -9.898051e+04               5    9.285494e+04   \n\n      mom_reward_avg  mom_reward_min  mom_reward_max  mom_reward_std  \n7       -9521.929530          -24235             155     7988.393527  \n8       -2489.773490           -4475              10     1283.988759  \n15      -2929.211864           -6100              65     1796.577395  \n43     -15662.177966          -32200              15     9789.926311  \n102     -2602.398305           -5740              35     1746.029977  \n192     -7061.771186          -15505              10     4867.344108  \n221    -10402.563667          -24855              15     7679.013739  \n248    -15626.655348          -32880               5     9852.050424  \n262    -17262.640068          -33845               5     9851.629123  \n294    -16208.149406          -29210               5     8736.894528  \n343     -9821.802721          -23220              65     7305.705879  \n407    -17352.069847          -34580               5    10013.784476  \n454     -2910.025554           -5840              10     1695.921691  \n487     -7215.136286          -14280               5     3150.332785  \n497     -2881.073254           -5780              10     1675.234803  \n540     -3302.892491           -6890              40     1987.416556  \n681    -17367.598291          -34865              10    10129.478994  \n696     -3203.538462           -6390              15     1836.574679  \n697     -5844.880342          -18605              80     5980.239498  \n764    -10509.555556          -26735              15     8740.302212  \n784    -16882.183219          -33415               5     9676.340555  \n825     -9108.198971          -22700              35     6918.863932  \n843    -11555.077453          -28185              80     9098.360782  \n873     -7460.502693          -16660              25     5135.710262  \n874    -14618.276481          -30855              15     9258.581397  \n879     -4881.565934          -13200              45     3944.220737  \n999     -1865.000000           -3735               5     1083.974169  \n1000    -6822.066667          -14725              25     4191.676251  \n1001    -1837.280000           -3880              35     1164.153345  \n1012    -3017.507042           -8005              10     2326.011911  \n1013    -3611.087571           -9480              10     2617.396235  \n1025    -2283.620690           -7010             100     2100.878007  \n1028    -6883.487544          -14020               5     4144.731286  \n1031    -3519.982143           -6300               5     1814.676304  \n1032    -1449.232143           -3060              10      934.315267  \n1039    -2863.457944           -5975               5     1811.103647  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cell_id</th>\n      <th>drift_score</th>\n      <th>quality_avg</th>\n      <th>quality_min</th>\n      <th>quality_max</th>\n      <th>quality_std</th>\n      <th>cum_reward_avg</th>\n      <th>cum_reward_max</th>\n      <th>cum_reward_std</th>\n      <th>mom_reward_avg</th>\n      <th>mom_reward_min</th>\n      <th>mom_reward_max</th>\n      <th>mom_reward_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>(13312,)</td>\n      <td>1.000</td>\n      <td>0.827806</td>\n      <td>0.683533</td>\n      <td>1.014011</td>\n      <td>0.051522</td>\n      <td>-1.488446e+06</td>\n      <td>5680</td>\n      <td>1.681490e+06</td>\n      <td>-9521.929530</td>\n      <td>-24235</td>\n      <td>155</td>\n      <td>7988.393527</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>(13311,)</td>\n      <td>1.000</td>\n      <td>0.766681</td>\n      <td>0.637207</td>\n      <td>1.072541</td>\n      <td>0.050251</td>\n      <td>-5.236529e+05</td>\n      <td>15</td>\n      <td>4.493878e+05</td>\n      <td>-2489.773490</td>\n      <td>-4475</td>\n      <td>10</td>\n      <td>1283.988759</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>(22975,)</td>\n      <td>0.875</td>\n      <td>0.851060</td>\n      <td>0.708378</td>\n      <td>0.965337</td>\n      <td>0.028175</td>\n      <td>-5.601129e+05</td>\n      <td>760</td>\n      <td>5.161057e+05</td>\n      <td>-2929.211864</td>\n      <td>-6100</td>\n      <td>65</td>\n      <td>1796.577395</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>(24233,)</td>\n      <td>1.000</td>\n      <td>0.779225</td>\n      <td>0.680422</td>\n      <td>1.389400</td>\n      <td>0.045879</td>\n      <td>-2.962463e+06</td>\n      <td>95</td>\n      <td>2.776694e+06</td>\n      <td>-15662.177966</td>\n      <td>-32200</td>\n      <td>15</td>\n      <td>9789.926311</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>(9737,)</td>\n      <td>0.875</td>\n      <td>0.836526</td>\n      <td>0.688055</td>\n      <td>1.260287</td>\n      <td>0.039131</td>\n      <td>-4.723727e+05</td>\n      <td>310</td>\n      <td>4.581045e+05</td>\n      <td>-2602.398305</td>\n      <td>-5740</td>\n      <td>35</td>\n      <td>1746.029977</td>\n    </tr>\n    <tr>\n      <th>192</th>\n      <td>(42857,)</td>\n      <td>0.875</td>\n      <td>0.901327</td>\n      <td>0.631919</td>\n      <td>1.170445</td>\n      <td>0.036514</td>\n      <td>-1.261592e+06</td>\n      <td>15</td>\n      <td>1.248601e+06</td>\n      <td>-7061.771186</td>\n      <td>-15505</td>\n      <td>10</td>\n      <td>4867.344108</td>\n    </tr>\n    <tr>\n      <th>221</th>\n      <td>(8916,)</td>\n      <td>0.875</td>\n      <td>0.868850</td>\n      <td>0.690507</td>\n      <td>0.966925</td>\n      <td>0.034120</td>\n      <td>-1.782831e+06</td>\n      <td>30</td>\n      <td>1.786634e+06</td>\n      <td>-10402.563667</td>\n      <td>-24855</td>\n      <td>15</td>\n      <td>7679.013739</td>\n    </tr>\n    <tr>\n      <th>248</th>\n      <td>(42856,)</td>\n      <td>0.875</td>\n      <td>0.925625</td>\n      <td>0.667989</td>\n      <td>1.060651</td>\n      <td>0.031276</td>\n      <td>-2.937212e+06</td>\n      <td>5</td>\n      <td>2.752871e+06</td>\n      <td>-15626.655348</td>\n      <td>-32880</td>\n      <td>5</td>\n      <td>9852.050424</td>\n    </tr>\n    <tr>\n      <th>262</th>\n      <td>(41872,)</td>\n      <td>0.875</td>\n      <td>0.802087</td>\n      <td>0.709027</td>\n      <td>1.287416</td>\n      <td>0.055670</td>\n      <td>-3.419002e+06</td>\n      <td>5</td>\n      <td>3.045949e+06</td>\n      <td>-17262.640068</td>\n      <td>-33845</td>\n      <td>5</td>\n      <td>9851.629123</td>\n    </tr>\n    <tr>\n      <th>294</th>\n      <td>(22971,)</td>\n      <td>1.000</td>\n      <td>0.791741</td>\n      <td>0.703038</td>\n      <td>1.269978</td>\n      <td>0.038279</td>\n      <td>-3.302312e+06</td>\n      <td>5</td>\n      <td>2.894209e+06</td>\n      <td>-16208.149406</td>\n      <td>-29210</td>\n      <td>5</td>\n      <td>8736.894528</td>\n    </tr>\n    <tr>\n      <th>343</th>\n      <td>(8915,)</td>\n      <td>0.875</td>\n      <td>0.867354</td>\n      <td>0.694822</td>\n      <td>1.047998</td>\n      <td>0.034472</td>\n      <td>-1.661120e+06</td>\n      <td>620</td>\n      <td>1.714007e+06</td>\n      <td>-9821.802721</td>\n      <td>-23220</td>\n      <td>65</td>\n      <td>7305.705879</td>\n    </tr>\n    <tr>\n      <th>407</th>\n      <td>(26191,)</td>\n      <td>0.875</td>\n      <td>0.911956</td>\n      <td>0.713553</td>\n      <td>1.094354</td>\n      <td>0.027854</td>\n      <td>-3.406125e+06</td>\n      <td>5</td>\n      <td>3.047013e+06</td>\n      <td>-17352.069847</td>\n      <td>-34580</td>\n      <td>5</td>\n      <td>10013.784476</td>\n    </tr>\n    <tr>\n      <th>454</th>\n      <td>(10942,)</td>\n      <td>0.875</td>\n      <td>0.771474</td>\n      <td>0.656311</td>\n      <td>1.059600</td>\n      <td>0.066389</td>\n      <td>-5.684150e+05</td>\n      <td>15</td>\n      <td>5.108068e+05</td>\n      <td>-2910.025554</td>\n      <td>-5840</td>\n      <td>10</td>\n      <td>1695.921691</td>\n    </tr>\n    <tr>\n      <th>487</th>\n      <td>(9442,)</td>\n      <td>0.875</td>\n      <td>0.816025</td>\n      <td>0.687247</td>\n      <td>1.143174</td>\n      <td>0.068671</td>\n      <td>-1.604065e+06</td>\n      <td>5</td>\n      <td>1.236551e+06</td>\n      <td>-7215.136286</td>\n      <td>-14280</td>\n      <td>5</td>\n      <td>3150.332785</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>(723,)</td>\n      <td>0.875</td>\n      <td>0.721824</td>\n      <td>0.645863</td>\n      <td>1.071824</td>\n      <td>0.033284</td>\n      <td>-5.634072e+05</td>\n      <td>15</td>\n      <td>5.055907e+05</td>\n      <td>-2881.073254</td>\n      <td>-5780</td>\n      <td>10</td>\n      <td>1675.234803</td>\n    </tr>\n    <tr>\n      <th>540</th>\n      <td>(7907,)</td>\n      <td>0.875</td>\n      <td>0.854747</td>\n      <td>0.700377</td>\n      <td>1.025181</td>\n      <td>0.035920</td>\n      <td>-6.343403e+05</td>\n      <td>205</td>\n      <td>5.750568e+05</td>\n      <td>-3302.892491</td>\n      <td>-6890</td>\n      <td>40</td>\n      <td>1987.416556</td>\n    </tr>\n    <tr>\n      <th>681</th>\n      <td>(24692,)</td>\n      <td>0.875</td>\n      <td>0.888115</td>\n      <td>0.738502</td>\n      <td>1.207841</td>\n      <td>0.083353</td>\n      <td>-3.379557e+06</td>\n      <td>15</td>\n      <td>3.038718e+06</td>\n      <td>-17367.598291</td>\n      <td>-34865</td>\n      <td>10</td>\n      <td>10129.478994</td>\n    </tr>\n    <tr>\n      <th>696</th>\n      <td>(756,)</td>\n      <td>0.875</td>\n      <td>0.816620</td>\n      <td>0.680187</td>\n      <td>1.133890</td>\n      <td>0.037189</td>\n      <td>-6.290347e+05</td>\n      <td>35</td>\n      <td>5.599607e+05</td>\n      <td>-3203.538462</td>\n      <td>-6390</td>\n      <td>15</td>\n      <td>1836.574679</td>\n    </tr>\n    <tr>\n      <th>697</th>\n      <td>(755,)</td>\n      <td>1.000</td>\n      <td>0.773461</td>\n      <td>0.664145</td>\n      <td>1.042994</td>\n      <td>0.041261</td>\n      <td>-7.507052e+05</td>\n      <td>3095</td>\n      <td>9.750655e+05</td>\n      <td>-5844.880342</td>\n      <td>-18605</td>\n      <td>80</td>\n      <td>5980.239498</td>\n    </tr>\n    <tr>\n      <th>764</th>\n      <td>(7905,)</td>\n      <td>1.000</td>\n      <td>0.892627</td>\n      <td>0.729374</td>\n      <td>1.393866</td>\n      <td>0.043907</td>\n      <td>-1.623378e+06</td>\n      <td>90</td>\n      <td>1.829413e+06</td>\n      <td>-10509.555556</td>\n      <td>-26735</td>\n      <td>15</td>\n      <td>8740.302212</td>\n    </tr>\n    <tr>\n      <th>784</th>\n      <td>(1914,)</td>\n      <td>1.000</td>\n      <td>0.777415</td>\n      <td>0.667302</td>\n      <td>1.420806</td>\n      <td>0.047290</td>\n      <td>-3.308313e+06</td>\n      <td>5</td>\n      <td>2.954363e+06</td>\n      <td>-16882.183219</td>\n      <td>-33415</td>\n      <td>5</td>\n      <td>9676.340555</td>\n    </tr>\n    <tr>\n      <th>825</th>\n      <td>(3316,)</td>\n      <td>0.875</td>\n      <td>0.866045</td>\n      <td>0.681269</td>\n      <td>1.256254</td>\n      <td>0.049204</td>\n      <td>-1.507354e+06</td>\n      <td>185</td>\n      <td>1.563316e+06</td>\n      <td>-9108.198971</td>\n      <td>-22700</td>\n      <td>35</td>\n      <td>6918.863932</td>\n    </tr>\n    <tr>\n      <th>843</th>\n      <td>(8067,)</td>\n      <td>0.875</td>\n      <td>0.871227</td>\n      <td>0.699260</td>\n      <td>1.060002</td>\n      <td>0.030143</td>\n      <td>-1.849260e+06</td>\n      <td>2685</td>\n      <td>2.007034e+06</td>\n      <td>-11555.077453</td>\n      <td>-28185</td>\n      <td>80</td>\n      <td>9098.360782</td>\n    </tr>\n    <tr>\n      <th>873</th>\n      <td>(8095,)</td>\n      <td>0.875</td>\n      <td>0.910326</td>\n      <td>0.728073</td>\n      <td>1.109251</td>\n      <td>0.042007</td>\n      <td>-1.258608e+06</td>\n      <td>95</td>\n      <td>1.238586e+06</td>\n      <td>-7460.502693</td>\n      <td>-16660</td>\n      <td>25</td>\n      <td>5135.710262</td>\n    </tr>\n    <tr>\n      <th>874</th>\n      <td>(8096,)</td>\n      <td>0.875</td>\n      <td>0.897001</td>\n      <td>0.680304</td>\n      <td>1.476828</td>\n      <td>0.056152</td>\n      <td>-2.591923e+06</td>\n      <td>45</td>\n      <td>2.435863e+06</td>\n      <td>-14618.276481</td>\n      <td>-30855</td>\n      <td>15</td>\n      <td>9258.581397</td>\n    </tr>\n    <tr>\n      <th>879</th>\n      <td>(8475,)</td>\n      <td>0.875</td>\n      <td>0.852101</td>\n      <td>0.715749</td>\n      <td>1.066042</td>\n      <td>0.037450</td>\n      <td>-7.254497e+05</td>\n      <td>740</td>\n      <td>7.709472e+05</td>\n      <td>-4881.565934</td>\n      <td>-13200</td>\n      <td>45</td>\n      <td>3944.220737</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>(13315,)</td>\n      <td>1.000</td>\n      <td>0.782756</td>\n      <td>0.683124</td>\n      <td>0.905337</td>\n      <td>0.027435</td>\n      <td>-2.334333e+05</td>\n      <td>5</td>\n      <td>2.093858e+05</td>\n      <td>-1865.000000</td>\n      <td>-3735</td>\n      <td>5</td>\n      <td>1083.974169</td>\n    </tr>\n    <tr>\n      <th>1000</th>\n      <td>(13317,)</td>\n      <td>1.000</td>\n      <td>0.811469</td>\n      <td>0.688337</td>\n      <td>0.902784</td>\n      <td>0.027808</td>\n      <td>-8.332817e+05</td>\n      <td>95</td>\n      <td>7.550594e+05</td>\n      <td>-6822.066667</td>\n      <td>-14725</td>\n      <td>25</td>\n      <td>4191.676251</td>\n    </tr>\n    <tr>\n      <th>1001</th>\n      <td>(13316,)</td>\n      <td>1.000</td>\n      <td>0.800225</td>\n      <td>0.674919</td>\n      <td>1.047584</td>\n      <td>0.045738</td>\n      <td>-2.197884e+05</td>\n      <td>185</td>\n      <td>2.051258e+05</td>\n      <td>-1837.280000</td>\n      <td>-3880</td>\n      <td>35</td>\n      <td>1164.153345</td>\n    </tr>\n    <tr>\n      <th>1012</th>\n      <td>(3336,)</td>\n      <td>1.000</td>\n      <td>0.848581</td>\n      <td>0.724462</td>\n      <td>1.063296</td>\n      <td>0.058009</td>\n      <td>-3.053709e+05</td>\n      <td>15</td>\n      <td>3.066482e+05</td>\n      <td>-3017.507042</td>\n      <td>-8005</td>\n      <td>10</td>\n      <td>2326.011911</td>\n    </tr>\n    <tr>\n      <th>1013</th>\n      <td>(8926,)</td>\n      <td>0.875</td>\n      <td>0.852417</td>\n      <td>0.719747</td>\n      <td>1.170471</td>\n      <td>0.065038</td>\n      <td>-3.803507e+05</td>\n      <td>15</td>\n      <td>3.670664e+05</td>\n      <td>-3611.087571</td>\n      <td>-9480</td>\n      <td>10</td>\n      <td>2617.396235</td>\n    </tr>\n    <tr>\n      <th>1025</th>\n      <td>(51357,)</td>\n      <td>0.875</td>\n      <td>0.848602</td>\n      <td>0.711222</td>\n      <td>0.960383</td>\n      <td>0.070595</td>\n      <td>-1.632883e+05</td>\n      <td>1460</td>\n      <td>1.921173e+05</td>\n      <td>-2283.620690</td>\n      <td>-7010</td>\n      <td>100</td>\n      <td>2100.878007</td>\n    </tr>\n    <tr>\n      <th>1028</th>\n      <td>(8641,)</td>\n      <td>1.000</td>\n      <td>0.859705</td>\n      <td>0.737558</td>\n      <td>1.309134</td>\n      <td>0.056698</td>\n      <td>-6.352608e+05</td>\n      <td>10</td>\n      <td>5.787370e+05</td>\n      <td>-6883.487544</td>\n      <td>-14020</td>\n      <td>5</td>\n      <td>4144.731286</td>\n    </tr>\n    <tr>\n      <th>1031</th>\n      <td>(8645,)</td>\n      <td>0.875</td>\n      <td>0.913622</td>\n      <td>0.696276</td>\n      <td>1.142639</td>\n      <td>0.039373</td>\n      <td>-3.489248e+05</td>\n      <td>5</td>\n      <td>2.982530e+05</td>\n      <td>-3519.982143</td>\n      <td>-6300</td>\n      <td>5</td>\n      <td>1814.676304</td>\n    </tr>\n    <tr>\n      <th>1032</th>\n      <td>(8647,)</td>\n      <td>0.875</td>\n      <td>0.904285</td>\n      <td>0.707715</td>\n      <td>1.134465</td>\n      <td>0.042725</td>\n      <td>-1.286449e+05</td>\n      <td>15</td>\n      <td>1.204264e+05</td>\n      <td>-1449.232143</td>\n      <td>-3060</td>\n      <td>10</td>\n      <td>934.315267</td>\n    </tr>\n    <tr>\n      <th>1039</th>\n      <td>(12483,)</td>\n      <td>0.875</td>\n      <td>0.883805</td>\n      <td>0.840871</td>\n      <td>0.929947</td>\n      <td>0.020493</td>\n      <td>-9.898051e+04</td>\n      <td>5</td>\n      <td>9.285494e+04</td>\n      <td>-2863.457944</td>\n      <td>-5975</td>\n      <td>5</td>\n      <td>1811.103647</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.mom_reward_max > 0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-05T15:03:43.794846377Z",
     "start_time": "2023-09-05T15:03:43.746273512Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
